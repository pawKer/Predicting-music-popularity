{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function    # (at top of module)\n",
    "import warnings\n",
    "#warnings.filterwarnings('always')\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import json\n",
    "import spotipy\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "from matplotlib.pyplot import figure\n",
    "import math\n",
    "import seaborn as sns\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in original data: 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>popularity</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>danceability</th>\n",
       "      <th>key</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>mode</th>\n",
       "      <th>youtube_view_count</th>\n",
       "      <th>youtube_video_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:5ygDXis42ncn6kYG14lEVG</td>\n",
       "      <td>Baby Shark</td>\n",
       "      <td>[Pinkfong]</td>\n",
       "      <td>77</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>115.062</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.825</td>\n",
       "      <td>7</td>\n",
       "      <td>96333</td>\n",
       "      <td>-3.651</td>\n",
       "      <td>0.520</td>\n",
       "      <td>1</td>\n",
       "      <td>1956582159</td>\n",
       "      <td>Baby Shark Dance | Sing and Dance! | Animal So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:7fa9MBXhVfQ8P8Df9OEbD8</td>\n",
       "      <td>Girls Like You (feat. Cardi B)</td>\n",
       "      <td>[Maroon 5, Cardi B]</td>\n",
       "      <td>86</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>124.959</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0</td>\n",
       "      <td>235545</td>\n",
       "      <td>-6.825</td>\n",
       "      <td>0.448</td>\n",
       "      <td>1</td>\n",
       "      <td>1300452389</td>\n",
       "      <td>Maroon 5 - Girls Like You ft. Cardi B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:6De0lHrwBfPfrhorm9q1Xl</td>\n",
       "      <td>Me Rehúso</td>\n",
       "      <td>[Danny Ocean]</td>\n",
       "      <td>83</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>104.823</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.744</td>\n",
       "      <td>1</td>\n",
       "      <td>205715</td>\n",
       "      <td>-6.327</td>\n",
       "      <td>0.426</td>\n",
       "      <td>1</td>\n",
       "      <td>1229501096</td>\n",
       "      <td>Danny Ocean -  Me Rehúso (Official Audio)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:1j6xOGusnyXq3l6IryKF3G</td>\n",
       "      <td>Déjala Que Vuelva (feat. Manuel Turizo)</td>\n",
       "      <td>[Piso 21, Manuel Turizo]</td>\n",
       "      <td>74</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>170.019</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.681</td>\n",
       "      <td>1</td>\n",
       "      <td>220117</td>\n",
       "      <td>-4.323</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1</td>\n",
       "      <td>1216075058</td>\n",
       "      <td>Piso 21 - Déjala Que Vuelva (feat. Manuel Turi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:2ijef6ni2amuunRoKTlgww</td>\n",
       "      <td>Sin Pijama</td>\n",
       "      <td>[Becky G, Natti Natasha]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>94.014</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4</td>\n",
       "      <td>0.791</td>\n",
       "      <td>11</td>\n",
       "      <td>188560</td>\n",
       "      <td>-3.695</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0</td>\n",
       "      <td>1071141995</td>\n",
       "      <td>Becky G Natti Natasha - Sin Pijama (Video Ofic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                song_id  \\\n",
       "0  spotify:track:5ygDXis42ncn6kYG14lEVG   \n",
       "1  spotify:track:7fa9MBXhVfQ8P8Df9OEbD8   \n",
       "2  spotify:track:6De0lHrwBfPfrhorm9q1Xl   \n",
       "3  spotify:track:1j6xOGusnyXq3l6IryKF3G   \n",
       "4  spotify:track:2ijef6ni2amuunRoKTlgww   \n",
       "\n",
       "                                song_title                    artist  \\\n",
       "0                               Baby Shark                [Pinkfong]   \n",
       "1           Girls Like You (feat. Cardi B)       [Maroon 5, Cardi B]   \n",
       "2                                Me Rehúso             [Danny Ocean]   \n",
       "3  Déjala Que Vuelva (feat. Manuel Turizo)  [Piso 21, Manuel Turizo]   \n",
       "4                               Sin Pijama  [Becky G, Natti Natasha]   \n",
       "\n",
       "   popularity  energy  liveness    tempo  speechiness  acousticness  \\\n",
       "0          77   0.840    0.3410  115.062       0.2270        0.2450   \n",
       "1          86   0.541    0.1300  124.959       0.0505        0.5680   \n",
       "2          83   0.804    0.0494  104.823       0.0677        0.0231   \n",
       "3          74   0.788    0.0753  170.019       0.0785        0.0482   \n",
       "4          90   0.745    0.1040   94.014       0.0464        0.3540   \n",
       "\n",
       "   instrumentalness  time_signature  danceability  key  duration  loudness  \\\n",
       "0          0.000000               4         0.825    7     96333    -3.651   \n",
       "1          0.000000               4         0.851    0    235545    -6.825   \n",
       "2          0.000000               4         0.744    1    205715    -6.327   \n",
       "3          0.000000               4         0.681    1    220117    -4.323   \n",
       "4          0.000029               4         0.791   11    188560    -3.695   \n",
       "\n",
       "   valence  mode  youtube_view_count  \\\n",
       "0    0.520     1          1956582159   \n",
       "1    0.448     1          1300452389   \n",
       "2    0.426     1          1229501096   \n",
       "3    0.839     1          1216075058   \n",
       "4    0.820     0          1071141995   \n",
       "\n",
       "                                 youtube_video_title  \n",
       "0  Baby Shark Dance | Sing and Dance! | Animal So...  \n",
       "1              Maroon 5 - Girls Like You ft. Cardi B  \n",
       "2          Danny Ocean -  Me Rehúso (Official Audio)  \n",
       "3  Piso 21 - Déjala Que Vuelva (feat. Manuel Turi...  \n",
       "4  Becky G Natti Natasha - Sin Pijama (Video Ofic...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the file\n",
    "data = pd.read_csv('data_500_entries_youtube.csv')\n",
    "print(\"Number of entries in original data: \" + str(len(data.index)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in original data after cleaning: 570\n"
     ]
    }
   ],
   "source": [
    "if 'song_id' in data.columns:\n",
    "    data = data.drop_duplicates(subset=['song_id'], keep='first')\n",
    "else:\n",
    "    data = data.drop_duplicates(subset=['song_title'], keep='first')\n",
    "    \n",
    "print(\"Number of entries in original data after cleaning: \" + str(len(data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in original data after cleaning: 570\n"
     ]
    }
   ],
   "source": [
    "data = data[data.popularity > 50]\n",
    "print(\"Number of entries in original data after cleaning: \" + str(len(data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of popular examples after thresholding :  47\n",
      "Number of not popular examples after thresholding :  523\n"
     ]
    }
   ],
   "source": [
    "from project_modules import *\n",
    "# Make a copy of the data to which we will ad labels and then remove any \n",
    "# columns that we will not need\n",
    "# This is currently a duplicate of the functionality above - could maybe only do this in one place\n",
    "\n",
    "final_data = label_data(data, 90)\n",
    "\n",
    "# Drop unnecessary columns from original data\n",
    "if 'song_id' in data.columns:\n",
    "    final_data.drop(['song_id', 'song_title', 'artist', 'popularity', 'youtube_video_title'], 1, inplace=True)\n",
    "else:\n",
    "    final_data.drop(['song_title', 'artist', 'popularity'], 1, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>danceability</th>\n",
       "      <th>key</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>mode</th>\n",
       "      <th>youtube_view_count</th>\n",
       "      <th>is_popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.838293</td>\n",
       "      <td>0.331118</td>\n",
       "      <td>0.360693</td>\n",
       "      <td>0.399286</td>\n",
       "      <td>0.247690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.789030</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.016514</td>\n",
       "      <td>0.807462</td>\n",
       "      <td>0.522258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1956582159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.502527</td>\n",
       "      <td>0.111965</td>\n",
       "      <td>0.431906</td>\n",
       "      <td>0.049366</td>\n",
       "      <td>0.574298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.825598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442256</td>\n",
       "      <td>0.594084</td>\n",
       "      <td>0.444083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1300452389</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.797866</td>\n",
       "      <td>0.028251</td>\n",
       "      <td>0.287019</td>\n",
       "      <td>0.083466</td>\n",
       "      <td>0.023312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.675105</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.351029</td>\n",
       "      <td>0.627563</td>\n",
       "      <td>0.420195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1229501096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.779899</td>\n",
       "      <td>0.055152</td>\n",
       "      <td>0.756132</td>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.586498</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.395074</td>\n",
       "      <td>0.762286</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1216075058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731611</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>0.209243</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.357908</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.741210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298565</td>\n",
       "      <td>0.804504</td>\n",
       "      <td>0.847991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1071141995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     energy  liveness     tempo  speechiness  acousticness  instrumentalness  \\\n",
       "0  0.838293  0.331118  0.360693     0.399286      0.247690          0.000000   \n",
       "1  0.502527  0.111965  0.431906     0.049366      0.574298          0.000000   \n",
       "2  0.797866  0.028251  0.287019     0.083466      0.023312          0.000000   \n",
       "3  0.779899  0.055152  0.756132     0.104877      0.048692          0.000000   \n",
       "4  0.731611  0.084961  0.209243     0.041237      0.357908          0.000032   \n",
       "\n",
       "   time_signature  danceability       key  duration  loudness   valence  mode  \\\n",
       "0            0.75      0.789030  0.636364  0.016514  0.807462  0.522258   1.0   \n",
       "1            0.75      0.825598  0.000000  0.442256  0.594084  0.444083   1.0   \n",
       "2            0.75      0.675105  0.090909  0.351029  0.627563  0.420195   1.0   \n",
       "3            0.75      0.586498  0.090909  0.395074  0.762286  0.868621   1.0   \n",
       "4            0.75      0.741210  1.000000  0.298565  0.804504  0.847991   0.0   \n",
       "\n",
       "   youtube_view_count  is_popular  \n",
       "0          1956582159           0  \n",
       "1          1300452389           0  \n",
       "2          1229501096           0  \n",
       "3          1216075058           0  \n",
       "4          1071141995           0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "\n",
    "COLUMNS_TO_SCALE = [\"energy\", \"liveness\", \"tempo\", \n",
    "                    \"speechiness\", \"acousticness\", \"instrumentalness\", \n",
    "                    \"time_signature\", \"danceability\", \"key\", \n",
    "                    \"duration\", \"loudness\", \"valence\", \"mode\"]\n",
    "# Keep data in a temp variable for testing\n",
    "scaled_data = scale_data_normalize(final_data, COLUMNS_TO_SCALE)\n",
    "\n",
    "# Copy data back\n",
    "final_data = scaled_data.copy()\n",
    "\n",
    "#Just to check that everything is fine\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in actual data: 570\n",
      "Number of entries in label data: 570\n"
     ]
    }
   ],
   "source": [
    "# X will be our examples and y will be our labels\n",
    "X = final_data.drop('is_popular', axis=1)\n",
    "y = final_data['is_popular']\n",
    "# Sanity checks\n",
    "print(\"Number of entries in actual data: \" + str(len(X.index)))\n",
    "print(\"Number of entries in label data: \" + str(len(y.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop this here because of high correlation with the our popularity metric\n",
    "# - popular songs on Spotify also have a high youtube view count\n",
    "X = X.drop('youtube_view_count', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>danceability</th>\n",
       "      <th>key</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.838293</td>\n",
       "      <td>0.331118</td>\n",
       "      <td>0.360693</td>\n",
       "      <td>0.399286</td>\n",
       "      <td>0.247690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.789030</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.016514</td>\n",
       "      <td>0.807462</td>\n",
       "      <td>0.522258</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.502527</td>\n",
       "      <td>0.111965</td>\n",
       "      <td>0.431906</td>\n",
       "      <td>0.049366</td>\n",
       "      <td>0.574298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.825598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442256</td>\n",
       "      <td>0.594084</td>\n",
       "      <td>0.444083</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.797866</td>\n",
       "      <td>0.028251</td>\n",
       "      <td>0.287019</td>\n",
       "      <td>0.083466</td>\n",
       "      <td>0.023312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.675105</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.351029</td>\n",
       "      <td>0.627563</td>\n",
       "      <td>0.420195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.779899</td>\n",
       "      <td>0.055152</td>\n",
       "      <td>0.756132</td>\n",
       "      <td>0.104877</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.586498</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.395074</td>\n",
       "      <td>0.762286</td>\n",
       "      <td>0.868621</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.731611</td>\n",
       "      <td>0.084961</td>\n",
       "      <td>0.209243</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.357908</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.741210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298565</td>\n",
       "      <td>0.804504</td>\n",
       "      <td>0.847991</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     energy  liveness     tempo  speechiness  acousticness  instrumentalness  \\\n",
       "0  0.838293  0.331118  0.360693     0.399286      0.247690          0.000000   \n",
       "1  0.502527  0.111965  0.431906     0.049366      0.574298          0.000000   \n",
       "2  0.797866  0.028251  0.287019     0.083466      0.023312          0.000000   \n",
       "3  0.779899  0.055152  0.756132     0.104877      0.048692          0.000000   \n",
       "4  0.731611  0.084961  0.209243     0.041237      0.357908          0.000032   \n",
       "\n",
       "   time_signature  danceability       key  duration  loudness   valence  mode  \n",
       "0            0.75      0.789030  0.636364  0.016514  0.807462  0.522258   1.0  \n",
       "1            0.75      0.825598  0.000000  0.442256  0.594084  0.444083   1.0  \n",
       "2            0.75      0.675105  0.090909  0.351029  0.627563  0.420195   1.0  \n",
       "3            0.75      0.586498  0.090909  0.395074  0.762286  0.868621   1.0  \n",
       "4            0.75      0.741210  1.000000  0.298565  0.804504  0.847991   0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8191\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "columns = [\"energy\", \"liveness\", \"tempo\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"time_signature\", \"danceability\",\n",
    "          \"key\", \"duration\", \"loudness\", \"valence\", \"mode\"]\n",
    "allSubsets = []\n",
    "total_no_subsets = 0\n",
    "for m in range(1, len(columns) + 1, 1):\n",
    "    subsets_with_m_elem = list(itertools.combinations(columns, m))\n",
    "    total_no_subsets += len(subsets_with_m_elem)\n",
    "    allSubsets.append(subsets_with_m_elem)\n",
    "print(total_no_subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations:  8191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "steps_taken = 0\n",
    "scores_list = []\n",
    "\n",
    "# Loop thorugh all the different subsets of 1,2,3, ..., (#features) elements\n",
    "for n_elem_subsets in range(0, len(columns), 1):\n",
    "    len_elem_subs = len(allSubsets[n_elem_subsets])\n",
    "    best_score = 0\n",
    "    feature_set = []\n",
    "    \n",
    "    # Loop through all the subsets of n_elem_subsets elements\n",
    "    for cur_comb in range(0, len_elem_subs, 1):\n",
    "        \n",
    "        # Get the data with the current subset of features\n",
    "        cur_data = X[list(allSubsets[n_elem_subsets][cur_comb])]\n",
    "        \n",
    "        # Transform to np array for faster computation\n",
    "        cur_data_np = np.array(cur_data)\n",
    "        \n",
    "        # Counter of number of interations\n",
    "        steps_taken += 1\n",
    "        \n",
    "        # Instantiate model\n",
    "        # model = LogisticRegression(class_weight='balanced',random_state=4)\n",
    "        model = svm.SVC(probability=False, gamma='scale', random_state=3, class_weight='balanced')\n",
    "        \n",
    "        # Instantiate cross validation strategy\n",
    "        cv = StratifiedKFold(n_splits=10, random_state=3)\n",
    "        \n",
    "        # Compute the cross valdation scores\n",
    "        scores = cross_val_score(model, cur_data_np, y, cv=cv, scoring='roc_auc')\n",
    "        \n",
    "        mean_score = scores.mean()\n",
    "        \n",
    "        # For brevity, we only keep the best feature subset of one size\n",
    "        # Alternatively, we could keep the scores for all the different combinations\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "    #Keep the best score in a list    \n",
    "    scores_list.append([feature_set, best_score])\n",
    "\n",
    "print(\"Number of iterations: \", steps_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd try using train test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations:  8191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "steps_taken = 0\n",
    "scores_list = []\n",
    "X_fs, X_test, y_fs, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "# Loop thorugh all the different subsets of 1,2,3, ..., (#features) elements\n",
    "for n_elem_subsets in range(0, len(columns), 1):\n",
    "    len_elem_subs = len(allSubsets[n_elem_subsets])\n",
    "    best_score = 0\n",
    "    best_feature_set = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Loop through all the subsets of n_elem_subsets elements\n",
    "    for cur_comb in range(0, len_elem_subs, 1):\n",
    "        \n",
    "        #X_fs, X_test, y_fs, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "        \n",
    "        # Current feature set\n",
    "        cur_feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "        \n",
    "        # Get the data with the current subset of features\n",
    "        cur_data = X_fs[cur_feature_set]\n",
    "        \n",
    "        # Transform to np array for faster computation\n",
    "        cur_data_np = np.array(cur_data)\n",
    "        cur_labels_np = np.array(y_fs)\n",
    "        # Counter of number of interations\n",
    "        steps_taken += 1\n",
    "        \n",
    "        # Instantiate model\n",
    "        model = LogisticRegression(class_weight='balanced',random_state=4)\n",
    "        # model = svm.SVC(probability=True, gamma='scale', random_state=3, class_weight='balanced')\n",
    "        \n",
    "        # Instantiate cross validation strategy\n",
    "        cv = StratifiedKFold(n_splits=10, random_state=3)\n",
    "        \n",
    "        scores = np.array([])\n",
    "        for train, test in cv.split(cur_data_np, cur_labels_np):\n",
    "            probas_ = model.fit(cur_data_np[train], cur_labels_np[train]).predict_proba(cur_data_np[test])\n",
    "            predicts = model.predict(cur_data_np[test])\n",
    "            scores = np.append(scores, roc_auc_score(cur_labels_np[test], probas_[:, 1]))\n",
    "        \n",
    "        mean_score = scores.mean()\n",
    "        \n",
    "        \n",
    "        y_pred_prob = model.predict_proba(X_test[cur_feature_set])[:,1]\n",
    "        test_after_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        \n",
    "        \n",
    "        # average_score = (float(mean_score) + test_after_auc)/2\n",
    "        # print(\"Curent score for {} features : {} | Test after score: {} | Average: {}\".format(len(cur_feature_set), mean_score, test_after_auc, average_score))\n",
    "        \n",
    "        # For brevity, we only keep the best feature subset of one size\n",
    "        # Alternatively, we could keep the scores for all the different combinations\n",
    "        if mean_score > best_score:\n",
    "            best_score = average_score\n",
    "            best_feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "        \n",
    "    #predictions = model.predict(X_test[feature_set])\n",
    "    \n",
    "        \n",
    "    #Keep the best score in a list    \n",
    "    scores_list.append([best_feature_set, best_score])\n",
    "\n",
    "print(\"Number of iterations: \", steps_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd try using train test validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations:  8191\n",
      "Number of iterations:  8191\n",
      "Number of iterations:  8191\n",
      "Number of iterations:  8191\n",
      "Number of iterations:  8191\n",
      "Number of iterations:  8191\n",
      "Number of iterations:  8191\n",
      "Number of iterations:  8191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-b544e25b1650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_data_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_labels_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[0mprobas_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_data_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_labels_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_data_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                 \u001b[0mpredicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_data_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_labels_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobas_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\imblearn\\pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\sklearn\\svm\\base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "models = [\n",
    "          {'title':\"Logistic regression\", 'model':LogisticRegression(random_state=3)},\n",
    "          {'title':\"Logistic regression balanced weights\", 'model':LogisticRegression(class_weight='balanced', random_state=3)},\n",
    "          {'title':\"Oversampling logistic regression\", 'model':make_pipeline_imb(SMOTE(random_state=4), LogisticRegression(random_state=3))},\n",
    "          {'title':\"Oversampling logistic regression balanced weights\", 'model':make_pipeline_imb(SMOTE(random_state=4), LogisticRegression(class_weight='balanced',random_state=3))},\n",
    "          {'title':\"KNN\", 'model':KNeighborsClassifier(n_neighbors = 17)},\n",
    "          {'title':\"Oversampling KNN\", 'model':make_pipeline_imb(SMOTE(random_state=4), KNeighborsClassifier(n_neighbors = 17))},\n",
    "          {'title':\"SVM\", 'model':svm.SVC(probability=True, gamma='scale', random_state=3)},\n",
    "          {'title':\"SVM balanced weights\", 'model':svm.SVC(probability=True, gamma='scale', random_state=3, class_weight='balanced')},\n",
    "          {'title':\"Oversampling SVM\", 'model':make_pipeline_imb(SMOTE(random_state=4), svm.SVC(probability=True, gamma='scale', random_state=3))}\n",
    "         ]\n",
    "models_scores_list = []\n",
    "\n",
    "X_fs, X_test, y_fs, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "for item in models:\n",
    "    steps_taken = 0\n",
    "    scores_list = []\n",
    "    # Loop thorugh all the different subsets of 1,2,3, ..., (#features) elements\n",
    "    for n_elem_subsets in range(0, len(columns), 1):\n",
    "        len_elem_subs = len(allSubsets[n_elem_subsets])\n",
    "        best_score = 0\n",
    "        best_feature_set = []\n",
    "        \n",
    "        # Loop through all the subsets of n_elem_subsets elements\n",
    "        for cur_comb in range(0, len_elem_subs, 1):\n",
    "\n",
    "            # Current feature set\n",
    "            cur_feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "\n",
    "            # Get the data with the current subset of features\n",
    "            cur_data = X_fs[cur_feature_set]\n",
    "\n",
    "            # Transform to np array for faster computation\n",
    "            cur_data_np = np.array(cur_data)\n",
    "            cur_labels_np = np.array(y_fs)\n",
    "            \n",
    "            # Counter of number of iterations\n",
    "            steps_taken += 1\n",
    "\n",
    "            # Instantiate model\n",
    "            model = item['model']\n",
    "            # model = svm.SVC(probability=True, gamma='scale', random_state=3, class_weight='balanced')\n",
    "\n",
    "            # Instantiate cross validation strategy\n",
    "            cv = StratifiedKFold(n_splits=10, random_state=3)\n",
    "\n",
    "            scores = np.array([])\n",
    "            for train, test in cv.split(cur_data_np, cur_labels_np):\n",
    "                probas_ = model.fit(cur_data_np[train], cur_labels_np[train]).predict_proba(cur_data_np[test])\n",
    "                predicts = model.predict(cur_data_np[test])\n",
    "                scores = np.append(scores, roc_auc_score(cur_labels_np[test], probas_[:, 1]))\n",
    "\n",
    "            mean_score = scores.mean()\n",
    "\n",
    "            # average_score = (float(mean_score) + test_after_auc)/2\n",
    "            # print(\"Curent score for {} features : {} | Test after score: {} | Average: {}\".format(len(cur_feature_set), mean_score, test_after_auc, average_score))\n",
    "\n",
    "            # For brevity, we only keep the best feature subset of one size\n",
    "            # Alternatively, we could keep the scores for all the different combinations\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "\n",
    "        #predictions = model.predict(X_test[feature_set])\n",
    "        model = item['model']\n",
    "        model.fit(X_fs[best_feature_set], y_fs)\n",
    "        y_pred_prob = model.predict_proba(X_test[best_feature_set])[:,1]\n",
    "        test_after_auc = roc_auc_score(y_test, y_pred_prob)   \n",
    "        #Keep the best score in a list    \n",
    "        scores_list.append([best_feature_set, test_after_auc])\n",
    "\n",
    "    print(\"Number of iterations: \", steps_taken)\n",
    "    models_scores_list.append([item['title'], scores_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n",
      "\n",
      "[['valence'], 0.62064459930313587]\n",
      "[['danceability', 'valence'], 0.63937282229965153]\n",
      "[['instrumentalness', 'danceability', 'valence'], 0.63850174216027866]\n",
      "[['acousticness', 'time_signature', 'danceability', 'valence'], 0.66898954703832747]\n",
      "[['acousticness', 'instrumentalness', 'time_signature', 'danceability', 'valence'], 0.66637630662020897]\n",
      "[['energy', 'tempo', 'time_signature', 'danceability', 'loudness', 'valence'], 0.64721254355400692]\n",
      "[['energy', 'tempo', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.61585365853658547]\n",
      "[['energy', 'tempo', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.61324041811846686]\n",
      "[['energy', 'liveness', 'tempo', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.61411149825783973]\n",
      "[['energy', 'liveness', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.58275261324041805]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence'], 0.6350174216027874]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence'], 0.62282229965156799]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.61759581881533099]\n",
      "\n",
      "Logistic regression balanced weights\n",
      "\n",
      "[['valence'], 0.62064459930313587]\n",
      "[['loudness', 'valence'], 0.64547038327526141]\n",
      "[['energy', 'loudness', 'valence'], 0.62195121951219501]\n",
      "[['energy', 'tempo', 'loudness', 'valence'], 0.64111498257839716]\n",
      "[['energy', 'tempo', 'danceability', 'loudness', 'valence'], 0.61846689895470375]\n",
      "[['energy', 'tempo', 'instrumentalness', 'danceability', 'loudness', 'valence'], 0.60888501742160284]\n",
      "[['energy', 'tempo', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.6097560975609756]\n",
      "[['energy', 'liveness', 'tempo', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.60888501742160273]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.64634146341463405]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.62543554006968638]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.6123693379790941]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence'], 0.60627177700348434]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.58885017421602792]\n",
      "\n",
      "Oversampling logistic regression\n",
      "\n",
      "[['valence'], 0.62064459930313587]\n",
      "[['loudness', 'valence'], 0.64895470383275267]\n",
      "[['energy', 'loudness', 'valence'], 0.61411149825783973]\n",
      "[['energy', 'danceability', 'loudness', 'valence'], 0.61236933797909399]\n",
      "[['energy', 'instrumentalness', 'danceability', 'loudness', 'valence'], 0.5993031358885017]\n",
      "[['energy', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.60017421602787446]\n",
      "[['energy', 'liveness', 'acousticness', 'instrumentalness', 'danceability', 'loudness', 'valence'], 0.62630662020905925]\n",
      "[['energy', 'liveness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.62282229965156799]\n",
      "[['energy', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.62456445993031351]\n",
      "[['energy', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence'], 0.6350174216027874]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'loudness', 'valence', 'mode'], 0.63240418118466901]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.60627177700348434]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.58972125435540068]\n",
      "\n",
      "Oversampling logistic regression balanced weights\n",
      "\n",
      "[['valence'], 0.62064459930313587]\n",
      "[['loudness', 'valence'], 0.64895470383275267]\n",
      "[['energy', 'loudness', 'valence'], 0.61411149825783973]\n",
      "[['energy', 'danceability', 'loudness', 'valence'], 0.61236933797909399]\n",
      "[['energy', 'instrumentalness', 'danceability', 'loudness', 'valence'], 0.5993031358885017]\n",
      "[['energy', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.60017421602787446]\n",
      "[['energy', 'liveness', 'acousticness', 'instrumentalness', 'danceability', 'loudness', 'valence'], 0.62630662020905925]\n",
      "[['energy', 'liveness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.62282229965156799]\n",
      "[['energy', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.62456445993031351]\n",
      "[['energy', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence'], 0.6350174216027874]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'loudness', 'valence', 'mode'], 0.63240418118466901]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.60627177700348434]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.58972125435540068]\n",
      "\n",
      "KNN\n",
      "\n",
      "[['liveness'], 0.5766550522648084]\n",
      "[['speechiness', 'loudness'], 0.53397212543554007]\n",
      "[['energy', 'speechiness', 'loudness'], 0.38632404181184665]\n",
      "[['energy', 'speechiness', 'acousticness', 'loudness'], 0.34581881533101044]\n",
      "[['energy', 'speechiness', 'acousticness', 'instrumentalness', 'loudness'], 0.34451219512195119]\n",
      "[['energy', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'loudness'], 0.36803135888501737]\n",
      "[['energy', 'liveness', 'speechiness', 'time_signature', 'duration', 'loudness', 'valence'], 0.62935540069686413]\n",
      "[['energy', 'liveness', 'acousticness', 'instrumentalness', 'time_signature', 'duration', 'loudness', 'valence'], 0.67944250871080147]\n",
      "[['energy', 'liveness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.72909407665505221]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.67421602787456447]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence', 'mode'], 0.70121951219512191]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence', 'mode'], 0.76132404181184665]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.57186411149825789]\n",
      "\n",
      "Oversampling KNN\n",
      "\n",
      "[['valence'], 0.60932055749128922]\n",
      "[['speechiness', 'loudness'], 0.58405923344947741]\n",
      "[['acousticness', 'loudness', 'valence'], 0.49433797909407662]\n",
      "[['acousticness', 'instrumentalness', 'loudness', 'valence'], 0.48911149825783967]\n",
      "[['acousticness', 'instrumentalness', 'time_signature', 'loudness', 'valence'], 0.50348432055749126]\n",
      "[['energy', 'liveness', 'acousticness', 'time_signature', 'loudness', 'valence'], 0.54529616724738672]\n",
      "[['energy', 'liveness', 'acousticness', 'instrumentalness', 'danceability', 'loudness', 'valence'], 0.60801393728222997]\n",
      "[['energy', 'liveness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.59799651567944256]\n",
      "[['liveness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence', 'mode'], 0.75217770034843212]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.71559233449477344]\n",
      "[['energy', 'liveness', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence', 'mode'], 0.78702090592334495]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence', 'mode'], 0.75043554006968649]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.58580139372822293]\n",
      "\n",
      "SVM\n",
      "\n",
      "[['liveness'], 0.40984320557491288]\n",
      "[['instrumentalness', 'loudness'], 0.46646341463414631]\n",
      "[['speechiness', 'duration', 'valence'], 0.39982578397212543]\n",
      "[['speechiness', 'time_signature', 'duration', 'valence'], 0.35017421602787457]\n",
      "[['energy', 'liveness', 'acousticness', 'loudness', 'valence'], 0.59320557491289194]\n",
      "[['energy', 'tempo', 'speechiness', 'instrumentalness', 'time_signature', 'loudness'], 0.43815331010452963]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'time_signature', 'loudness', 'valence'], 0.62020905923344949]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'loudness', 'valence'], 0.69425087108013939]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.62804878048780477]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'loudness', 'valence'], 0.62369337979094064]\n",
      "[['energy', 'liveness', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence', 'mode'], 0.62891986062717775]\n",
      "[['energy', 'liveness', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.55139372822299648]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.58623693379790942]\n",
      "\n",
      "SVM balanced weights\n",
      "\n",
      "[['valence'], 0.59277003484320556]\n",
      "[['liveness', 'valence'], 0.61846689895470375]\n",
      "[['liveness', 'tempo', 'valence'], 0.68205574912891986]\n",
      "[['energy', 'tempo', 'loudness', 'valence'], 0.59581881533101044]\n",
      "[['energy', 'tempo', 'danceability', 'loudness', 'valence'], 0.61933797909407673]\n",
      "[['energy', 'tempo', 'acousticness', 'danceability', 'loudness', 'valence'], 0.64111498257839727]\n",
      "[['energy', 'tempo', 'acousticness', 'danceability', 'duration', 'loudness', 'valence'], 0.58623693379790942]\n",
      "[['energy', 'tempo', 'acousticness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.59233449477351918]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'danceability', 'duration', 'loudness', 'valence'], 0.59843205574912894]\n",
      "[['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.60278745644599308]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'duration', 'loudness', 'valence'], 0.5966898954703832]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence'], 0.59233449477351918]\n",
      "[['energy', 'liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'duration', 'loudness', 'valence', 'mode'], 0.5740418118466899]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print feature sets with best scores\n",
    "for cur_list in models_scores_list:\n",
    "    print(cur_list[0])\n",
    "    \n",
    "    print()\n",
    "    for score in cur_list[1]:\n",
    "        print(score)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tempo', 'acousticness', 'instrumentalness', 'valence', 'youtube_view_count']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=5)\n",
    "\n",
    "sel = SelectKBest(chi2, k = 5)\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "selected = sel.transform(X_train)\n",
    "#print(selected.shape)\n",
    "#print(X_train.shape)\n",
    "\n",
    "mask = sel.get_support() #list of booleans\n",
    "new_features = [] # The list of your K best features\n",
    "\n",
    "for bool, feature in zip(mask, columns):\n",
    "    if bool:\n",
    "        new_features.append(feature)\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.14213373094378604, 0.00066591728398211357)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(pearsonr(X['valence'], y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability 0.0\n",
      "key 0.0\n",
      "loudness 0.0\n",
      "mode 0.0\n",
      "time_signature 0.0\n",
      "instrumentalness 0.000894091894609\n",
      "duration 0.00394051170442\n",
      "valence 0.0052091734451\n",
      "acousticness 0.0064337769563\n",
      "energy 0.00782331422319\n",
      "liveness 0.0090491953887\n",
      "speechiness 0.010764084423\n",
      "tempo 0.0248102732113\n",
      "youtube_view_count 0.0767909877769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "feature_scores = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, columns)):\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JMI for energy is 0.153979386369\n",
      "JMI for liveness is 0.244123657293\n",
      "JMI for tempo is 0.562840650098\n",
      "JMI for speechiness is 0.757750987721\n",
      "JMI for acousticness is 0.848489219212\n",
      "JMI for instrumentalness is 0.932732553967\n",
      "JMI for time_signature is 1.01245219852\n",
      "JMI for danceability is 1.01245219852\n",
      "JMI for key is 1.02259786753\n",
      "JMI for duration is 1.07382451968\n",
      "JMI for loudness is 1.07382451968\n",
      "JMI for valence is 1.19773610499\n",
      "JMI for mode is 1.39765128205\n",
      "JMI for youtube_view_count is 2.39593412315\n"
     ]
    }
   ],
   "source": [
    "columns = [\"energy\", \"liveness\", \"tempo\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"time_signature\", \"danceability\",\n",
    "          \"key\", \"duration\", \"loudness\", \"valence\", \"mode\", 'youtube_view_count']\n",
    "jmi = 0\n",
    "for col in columns:\n",
    "    for next_col in columns:\n",
    "        if col != next_col:\n",
    "            jmi += mutual_info_classif(X_train[[col, next_col]], y_train)[0]\n",
    "            #print(col, next_col)\n",
    "    print(\"JMI for {} is {}\".format(col, jmi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loudness 0.00568406128276\n",
      "speechiness 0.0270260029669\n",
      "time_signature 0.0319876660937\n",
      "duration 0.185910425031\n",
      "liveness 0.18892589418\n",
      "mode 0.280688060472\n",
      "instrumentalness 0.499371675555\n",
      "key 0.824257236616\n",
      "danceability 1.7323999922\n",
      "acousticness 2.37542137751\n",
      "energy 2.55239718842\n",
      "tempo 2.90091388799\n",
      "valence 9.47236752793\n",
      "youtube_view_count 16.7542628848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "feature_scores = f_classif(X_train, y_train)[0]\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, columns)):\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.100676893575\n",
      "test score:  -0.0245044946864\n",
      "number of features used:  5\n",
      "Alpha(amount of penalization) chosen by CV:  0.00255186972012\n",
      "['tempo', 'acousticness', 'danceability', 'valence', 'youtube_view_count']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "lasso = LassoCV(cv=StratifiedKFold(n_splits=10, random_state=3), random_state=3)\n",
    "lasso.fit(X_train,y_train)\n",
    "train_score=lasso.score(X_train,y_train)\n",
    "test_score=lasso.score(X_test,y_test)\n",
    "coeff_used = np.sum(lasso.coef_!=0)\n",
    "\n",
    "print(\"training score:\", train_score)\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)\n",
    "\n",
    "#print(lasso.coef_)\n",
    "\n",
    "ind = 0\n",
    "sel_f = []\n",
    "for coef in lasso.coef_:\n",
    "    if coef != 0:\n",
    "        sel_f.append(columns[ind]) \n",
    "    ind += 1\n",
    "print(\"Alpha(amount of penalization) chosen by CV: \", lasso.alpha_)\n",
    "print(sel_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.733333333333\n",
      "test score:  0.754385964912\n",
      "number of features used:  8\n",
      "[[-0.94486389  0.         -0.7416253   0.         -0.74908941  0.          0.\n",
      "   1.26044335  0.          0.          1.61691455 -3.32279006  0.21806523\n",
      "   6.60718735]]\n",
      "['energy', 'tempo', 'acousticness', 'danceability', 'loudness', 'valence', 'mode', 'youtube_view_count']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "loglasso = LogisticRegression(penalty='l1', class_weight='balanced', random_state=3)\n",
    "loglasso.fit(X_train,y_train)\n",
    "train_score=loglasso.score(X_train,y_train)\n",
    "test_score=loglasso.score(X_test,y_test)\n",
    "coeff_used = np.sum(loglasso.coef_!=0)\n",
    "\n",
    "print(\"training score:\", train_score)\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)\n",
    "\n",
    "print(loglasso.coef_)\n",
    "\n",
    "ind = 0\n",
    "sel_f = []\n",
    "for coef in loglasso.coef_[0]:\n",
    "    if coef != 0:\n",
    "        sel_f.append(columns[ind]) \n",
    "    ind += 1\n",
    "print(sel_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
