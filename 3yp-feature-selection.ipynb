{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function    # (at top of module)\n",
    "import warnings\n",
    "#warnings.filterwarnings('always')\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import json\n",
    "import spotipy\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "from matplotlib.pyplot import figure\n",
    "import math\n",
    "import seaborn as sns\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in original data: 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>popularity</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>danceability</th>\n",
       "      <th>key</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>mode</th>\n",
       "      <th>youtube_view_count</th>\n",
       "      <th>youtube_video_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:5ygDXis42ncn6kYG14lEVG</td>\n",
       "      <td>Baby Shark</td>\n",
       "      <td>[Pinkfong]</td>\n",
       "      <td>77</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>115.062</td>\n",
       "      <td>0.2270</td>\n",
       "      <td>0.2450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.825</td>\n",
       "      <td>7</td>\n",
       "      <td>96333</td>\n",
       "      <td>-3.651</td>\n",
       "      <td>0.520</td>\n",
       "      <td>1</td>\n",
       "      <td>1956582159</td>\n",
       "      <td>Baby Shark Dance | Sing and Dance! | Animal So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:7fa9MBXhVfQ8P8Df9OEbD8</td>\n",
       "      <td>Girls Like You (feat. Cardi B)</td>\n",
       "      <td>[Maroon 5, Cardi B]</td>\n",
       "      <td>86</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>124.959</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0</td>\n",
       "      <td>235545</td>\n",
       "      <td>-6.825</td>\n",
       "      <td>0.448</td>\n",
       "      <td>1</td>\n",
       "      <td>1300452389</td>\n",
       "      <td>Maroon 5 - Girls Like You ft. Cardi B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:6De0lHrwBfPfrhorm9q1Xl</td>\n",
       "      <td>Me Rehúso</td>\n",
       "      <td>[Danny Ocean]</td>\n",
       "      <td>83</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>104.823</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.744</td>\n",
       "      <td>1</td>\n",
       "      <td>205715</td>\n",
       "      <td>-6.327</td>\n",
       "      <td>0.426</td>\n",
       "      <td>1</td>\n",
       "      <td>1229501096</td>\n",
       "      <td>Danny Ocean -  Me Rehúso (Official Audio)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:1j6xOGusnyXq3l6IryKF3G</td>\n",
       "      <td>Déjala Que Vuelva (feat. Manuel Turizo)</td>\n",
       "      <td>[Piso 21, Manuel Turizo]</td>\n",
       "      <td>74</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>170.019</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.681</td>\n",
       "      <td>1</td>\n",
       "      <td>220117</td>\n",
       "      <td>-4.323</td>\n",
       "      <td>0.839</td>\n",
       "      <td>1</td>\n",
       "      <td>1216075058</td>\n",
       "      <td>Piso 21 - Déjala Que Vuelva (feat. Manuel Turi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:2ijef6ni2amuunRoKTlgww</td>\n",
       "      <td>Sin Pijama</td>\n",
       "      <td>[Becky G, Natti Natasha]</td>\n",
       "      <td>90</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>94.014</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4</td>\n",
       "      <td>0.791</td>\n",
       "      <td>11</td>\n",
       "      <td>188560</td>\n",
       "      <td>-3.695</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0</td>\n",
       "      <td>1071141995</td>\n",
       "      <td>Becky G Natti Natasha - Sin Pijama (Video Ofic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                song_id  \\\n",
       "0  spotify:track:5ygDXis42ncn6kYG14lEVG   \n",
       "1  spotify:track:7fa9MBXhVfQ8P8Df9OEbD8   \n",
       "2  spotify:track:6De0lHrwBfPfrhorm9q1Xl   \n",
       "3  spotify:track:1j6xOGusnyXq3l6IryKF3G   \n",
       "4  spotify:track:2ijef6ni2amuunRoKTlgww   \n",
       "\n",
       "                                song_title                    artist  \\\n",
       "0                               Baby Shark                [Pinkfong]   \n",
       "1           Girls Like You (feat. Cardi B)       [Maroon 5, Cardi B]   \n",
       "2                                Me Rehúso             [Danny Ocean]   \n",
       "3  Déjala Que Vuelva (feat. Manuel Turizo)  [Piso 21, Manuel Turizo]   \n",
       "4                               Sin Pijama  [Becky G, Natti Natasha]   \n",
       "\n",
       "   popularity  energy  liveness    tempo  speechiness  acousticness  \\\n",
       "0          77   0.840    0.3410  115.062       0.2270        0.2450   \n",
       "1          86   0.541    0.1300  124.959       0.0505        0.5680   \n",
       "2          83   0.804    0.0494  104.823       0.0677        0.0231   \n",
       "3          74   0.788    0.0753  170.019       0.0785        0.0482   \n",
       "4          90   0.745    0.1040   94.014       0.0464        0.3540   \n",
       "\n",
       "   instrumentalness  time_signature  danceability  key  duration  loudness  \\\n",
       "0          0.000000               4         0.825    7     96333    -3.651   \n",
       "1          0.000000               4         0.851    0    235545    -6.825   \n",
       "2          0.000000               4         0.744    1    205715    -6.327   \n",
       "3          0.000000               4         0.681    1    220117    -4.323   \n",
       "4          0.000029               4         0.791   11    188560    -3.695   \n",
       "\n",
       "   valence  mode  youtube_view_count  \\\n",
       "0    0.520     1          1956582159   \n",
       "1    0.448     1          1300452389   \n",
       "2    0.426     1          1229501096   \n",
       "3    0.839     1          1216075058   \n",
       "4    0.820     0          1071141995   \n",
       "\n",
       "                                 youtube_video_title  \n",
       "0  Baby Shark Dance | Sing and Dance! | Animal So...  \n",
       "1              Maroon 5 - Girls Like You ft. Cardi B  \n",
       "2          Danny Ocean -  Me Rehúso (Official Audio)  \n",
       "3  Piso 21 - Déjala Que Vuelva (feat. Manuel Turi...  \n",
       "4  Becky G Natti Natasha - Sin Pijama (Video Ofic...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the file\n",
    "data = pd.read_csv('Data/data_500_entries_youtube.csv')\n",
    "print(\"Number of entries in original data: \" + str(len(data.index)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in original data after cleaning: 570\n"
     ]
    }
   ],
   "source": [
    "if 'song_id' in data.columns:\n",
    "    data = data.drop_duplicates(subset=['song_id'], keep='first')\n",
    "else:\n",
    "    data = data.drop_duplicates(subset=['song_title'], keep='first')\n",
    "    \n",
    "print(\"Number of entries in original data after cleaning: \" + str(len(data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in original data after cleaning: 570\n"
     ]
    }
   ],
   "source": [
    "#data = data[data.popularity > 50]\n",
    "print(\"Number of entries in original data after cleaning: \" + str(len(data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of popular examples after thresholding :  55\n",
      "Number of not popular examples after thresholding :  515\n"
     ]
    }
   ],
   "source": [
    "from project_modules import *\n",
    "# Make a copy of the data to which we will ad labels and then remove any \n",
    "# columns that we will not need\n",
    "# This is currently a duplicate of the functionality above - could maybe only do this in one place\n",
    "\n",
    "final_data = label_data(data, 89)\n",
    "\n",
    "# Drop unnecessary columns from original data\n",
    "if 'total_no_streams' in data.columns:\n",
    "    final_data.drop(['song_id', 'song_title', 'artist', 'popularity', 'total_no_streams', 'youtube_view_count', 'youtube_video_title'], 1, inplace=True)\n",
    "else:\n",
    "    final_data.drop(['song_id','song_title', 'artist', 'popularity', 'youtube_view_count', 'youtube_video_title'], 1, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in actual data: 570\n",
      "Number of entries in label data: 570\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X will be our examples and y will be our labels\n",
    "X = final_data.drop('is_popular', axis=1)\n",
    "y = final_data['is_popular']\n",
    "X_fs, X_test, y_fs, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "# Sanity checks\n",
    "print(\"Number of entries in actual data: \" + str(len(X.index)))\n",
    "print(\"Number of entries in label data: \" + str(len(y.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Python27\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n",
      "C:\\Python27\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "\n",
    "COLUMNS_TO_SCALE = [\"energy\", \"liveness\", \"tempo\", \n",
    "                    \"speechiness\", \"acousticness\", \"instrumentalness\", \n",
    "                    \"time_signature\", \"danceability\", \"key\", \n",
    "                    \"duration\", \"loudness\", \"valence\", \"mode\"]\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_fs)\n",
    "\n",
    "# Copy data back\n",
    "X_fs = pd.DataFrame(scaler.transform(X_fs), columns=COLUMNS_TO_SCALE)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=COLUMNS_TO_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>danceability</th>\n",
       "      <th>key</th>\n",
       "      <th>duration</th>\n",
       "      <th>loudness</th>\n",
       "      <th>valence</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.240504</td>\n",
       "      <td>-0.369356</td>\n",
       "      <td>-1.578673</td>\n",
       "      <td>0.116411</td>\n",
       "      <td>-1.025474</td>\n",
       "      <td>1.356015</td>\n",
       "      <td>0.071422</td>\n",
       "      <td>-2.064129</td>\n",
       "      <td>-1.176486</td>\n",
       "      <td>-0.247486</td>\n",
       "      <td>0.054595</td>\n",
       "      <td>-0.232382</td>\n",
       "      <td>0.868243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.970713</td>\n",
       "      <td>1.074736</td>\n",
       "      <td>2.004555</td>\n",
       "      <td>0.537450</td>\n",
       "      <td>-0.833710</td>\n",
       "      <td>-0.133054</td>\n",
       "      <td>0.071422</td>\n",
       "      <td>-0.360571</td>\n",
       "      <td>1.302107</td>\n",
       "      <td>0.034933</td>\n",
       "      <td>-1.553240</td>\n",
       "      <td>0.324707</td>\n",
       "      <td>-1.151751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.410927</td>\n",
       "      <td>-0.421869</td>\n",
       "      <td>-0.135178</td>\n",
       "      <td>-0.918407</td>\n",
       "      <td>-1.034783</td>\n",
       "      <td>-0.133171</td>\n",
       "      <td>0.071422</td>\n",
       "      <td>-0.230703</td>\n",
       "      <td>-1.176486</td>\n",
       "      <td>1.940544</td>\n",
       "      <td>-0.766789</td>\n",
       "      <td>-0.548065</td>\n",
       "      <td>-1.151751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.228158</td>\n",
       "      <td>-0.526894</td>\n",
       "      <td>0.802764</td>\n",
       "      <td>0.677796</td>\n",
       "      <td>-0.661680</td>\n",
       "      <td>-0.133171</td>\n",
       "      <td>0.071422</td>\n",
       "      <td>0.304047</td>\n",
       "      <td>-1.176486</td>\n",
       "      <td>2.119036</td>\n",
       "      <td>-0.131561</td>\n",
       "      <td>-0.603774</td>\n",
       "      <td>0.868243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.179466</td>\n",
       "      <td>0.182024</td>\n",
       "      <td>0.065644</td>\n",
       "      <td>-0.507661</td>\n",
       "      <td>-0.492224</td>\n",
       "      <td>-0.133093</td>\n",
       "      <td>0.071422</td>\n",
       "      <td>0.739485</td>\n",
       "      <td>-0.074889</td>\n",
       "      <td>0.088988</td>\n",
       "      <td>-0.730937</td>\n",
       "      <td>1.104630</td>\n",
       "      <td>0.868243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     energy  liveness     tempo  speechiness  acousticness  instrumentalness  \\\n",
       "0  0.240504 -0.369356 -1.578673     0.116411     -1.025474          1.356015   \n",
       "1 -0.970713  1.074736  2.004555     0.537450     -0.833710         -0.133054   \n",
       "2  0.410927 -0.421869 -0.135178    -0.918407     -1.034783         -0.133171   \n",
       "3 -0.228158 -0.526894  0.802764     0.677796     -0.661680         -0.133171   \n",
       "4 -0.179466  0.182024  0.065644    -0.507661     -0.492224         -0.133093   \n",
       "\n",
       "   time_signature  danceability       key  duration  loudness   valence  \\\n",
       "0        0.071422     -2.064129 -1.176486 -0.247486  0.054595 -0.232382   \n",
       "1        0.071422     -0.360571  1.302107  0.034933 -1.553240  0.324707   \n",
       "2        0.071422     -0.230703 -1.176486  1.940544 -0.766789 -0.548065   \n",
       "3        0.071422      0.304047 -1.176486  2.119036 -0.131561 -0.603774   \n",
       "4        0.071422      0.739485 -0.074889  0.088988 -0.730937  1.104630   \n",
       "\n",
       "       mode  \n",
       "0  0.868243  \n",
       "1 -1.151751  \n",
       "2 -1.151751  \n",
       "3  0.868243  \n",
       "4  0.868243  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating all the different possible feature subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8191\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "columns = [\"energy\", \"liveness\", \"tempo\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"time_signature\", \"danceability\",\n",
    "          \"key\", \"duration\", \"loudness\", \"valence\", \"mode\"]\n",
    "allSubsets = []\n",
    "total_no_subsets = 0\n",
    "for m in range(1, len(columns) + 1, 1):\n",
    "    subsets_with_m_elem = list(itertools.combinations(columns, m))\n",
    "    total_no_subsets += len(subsets_with_m_elem)\n",
    "    allSubsets.append(subsets_with_m_elem)\n",
    "print(total_no_subsets)\n",
    "#print(allSubsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(fs_scores):\n",
    "\n",
    "    # Print feature sets with best scores\n",
    "    for cur_list in fs_scores:\n",
    "        print(cur_list[0])\n",
    "        print()\n",
    "        \n",
    "        max_score_gen = 0\n",
    "        max_score_cv = 0\n",
    "        score_cv = 0\n",
    "        score_gen = 0\n",
    "        for i in range(0, len(cur_list[1]), 1):\n",
    "            cur_score_gen = cur_list[1][i][1]\n",
    "            cur_score_cv = cur_list[1][i][2]\n",
    "\n",
    "            if cur_score_gen > max_score_gen:\n",
    "                max_score_gen = cur_score_gen\n",
    "                score_cv = cur_score_cv\n",
    "                sel_feature_set_gen = cur_list[1][i][0]\n",
    "\n",
    "            if cur_score_cv > max_score_cv:\n",
    "                max_score_cv = cur_score_cv\n",
    "                score_gen = cur_score_gen\n",
    "                sel_feature_set_cv = cur_list[1][i][0]\n",
    "        \n",
    "        print(\"Max generalized score: \")\n",
    "        print(max_score_gen)\n",
    "        print(\"Average cv score for that feature subset: \")\n",
    "        print(score_cv)\n",
    "        print()\n",
    "        print(sel_feature_set_gen)\n",
    "        print(\"-------------------\")\n",
    "        print(\"Max average cv score: \")\n",
    "        print(max_score_cv)\n",
    "        print(\"Generalized score for that feature subset: \")\n",
    "        print(score_gen)\n",
    "        print()\n",
    "        print(sel_feature_set_cv)\n",
    "        print()\n",
    "        print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing same size feature subsets against eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "models = [\n",
    "          {'title':\"Logistic regression\", 'model':LogisticRegression(random_state=3)},\n",
    "          {'title':\"Logistic regression balanced weights\", 'model':LogisticRegression(class_weight='balanced', random_state=3)},\n",
    "          {'title':\"Oversampling logistic regression\", 'model':make_pipeline_imb(SMOTE(random_state=4), LogisticRegression(random_state=3))},\n",
    "          {'title':\"Oversampling logistic regression balanced weights\", 'model':make_pipeline_imb(SMOTE(random_state=4), LogisticRegression(class_weight='balanced',random_state=3))},\n",
    "          {'title':\"KNN\", 'model':KNeighborsClassifier(n_neighbors = 17)},\n",
    "          {'title':\"Oversampling KNN\", 'model':make_pipeline_imb(SMOTE(random_state=4), KNeighborsClassifier(n_neighbors = 17))},\n",
    "          {'title':\"SVM\", 'model':svm.SVC(probability=True, gamma='scale', random_state=3)},\n",
    "          {'title':\"SVM balanced weights\", 'model':svm.SVC(probability=True, gamma='scale', random_state=3, class_weight='balanced')},\n",
    "          {'title':\"Oversampling SVM\", 'model':make_pipeline_imb(SMOTE(random_state=4), svm.SVC(probability=True, gamma='scale', random_state=3))}\n",
    "         ]\n",
    "models_scores_list = []\n",
    "\n",
    "X_fs, X_test, y_fs, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "for item in models:\n",
    "    steps_taken = 0\n",
    "    scores_list = []\n",
    "    # Loop thorugh all the different subsets of 1,2,3, ..., (#features) elements\n",
    "    for n_elem_subsets in range(0, len(columns), 1):\n",
    "        len_elem_subs = len(allSubsets[n_elem_subsets])\n",
    "        best_score = 0\n",
    "        best_feature_set = []\n",
    "        \n",
    "        # Loop through all the subsets of n_elem_subsets elements\n",
    "        for cur_comb in range(0, len_elem_subs, 1):\n",
    "\n",
    "            # Current feature set\n",
    "            cur_feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "\n",
    "            # Get the data with the current subset of features\n",
    "            cur_data = X_fs[cur_feature_set]\n",
    "\n",
    "            # Transform to np array for faster computation\n",
    "            cur_data_np = np.array(cur_data)\n",
    "            cur_labels_np = np.array(y_fs)\n",
    "            \n",
    "            # Counter of number of iterations\n",
    "            steps_taken += 1\n",
    "\n",
    "            # Instantiate model\n",
    "            model = item['model']\n",
    "            # model = svm.SVC(probability=True, gamma='scale', random_state=3, class_weight='balanced')\n",
    "\n",
    "            # Instantiate cross validation strategy\n",
    "            cv = StratifiedKFold(n_splits=10, random_state=3)\n",
    "\n",
    "            scores = np.array([])\n",
    "            for train, test in cv.split(cur_data_np, cur_labels_np):\n",
    "                probas_ = model.fit(cur_data_np[train], cur_labels_np[train]).predict_proba(cur_data_np[test])\n",
    "                predicts = model.predict(cur_data_np[test])\n",
    "                scores = np.append(scores, roc_auc_score(cur_labels_np[test], probas_[:, 1]))\n",
    "\n",
    "            mean_score = scores.mean()\n",
    "\n",
    "            # average_score = (float(mean_score) + test_after_auc)/2\n",
    "            # print(\"Curent score for {} features : {} | Test after score: {} | Average: {}\".format(len(cur_feature_set), mean_score, test_after_auc, average_score))\n",
    "\n",
    "            # For brevity, we only keep the best feature subset of one size\n",
    "            # Alternatively, we could keep the scores for all the different combinations\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "\n",
    "        #predictions = model.predict(X_test[feature_set])\n",
    "        model = item['model']\n",
    "        model.fit(X_fs[best_feature_set], y_fs)\n",
    "        y_pred_prob = model.predict_proba(X_test[best_feature_set])[:,1]\n",
    "        test_after_auc = roc_auc_score(y_test, y_pred_prob)   \n",
    "        #Keep the best score in a list    \n",
    "        scores_list.append([best_feature_set, test_after_auc])\n",
    "\n",
    "    print(\"Number of iterations: \", steps_taken)\n",
    "    models_scores_list.append([item['title'], scores_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring looks like: \n",
    "[Model Name, [feature subset, generalize score, average cv score]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores(models_scores_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing all subsets against eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python27\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models = [\n",
    "#          {'title':\"Logistic regression\", 'model':LogisticRegression(random_state=3), 'feature_set':['liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'danceability', 'key', 'loudness', 'valence']},\n",
    "#           {'title':\"Logistic regression balanced weights\", 'model':LogisticRegression(class_weight='balanced', n_jobs=-1, solver=\"lbfgs\"), 'feature_set':['tempo', 'acousticness', 'danceability', 'valence']},\n",
    "#          {'title':\"Oversampling logistic regression\", 'model':make_pipeline_imb(SMOTE(random_state=4), LogisticRegression(random_state=3, n_jobs=-1)), 'feature_set':['tempo', 'acousticness', 'danceability', 'key', 'valence']},\n",
    "#          {'title':\"Oversampling logistic regression balanced weights\", 'model':make_pipeline_imb(SMOTE(random_state=4), LogisticRegression(class_weight='balanced',random_state=3)), 'feature_set':['tempo', 'acousticness', 'danceability', 'key', 'valence']},\n",
    "#          {'title':\"KNN\", 'model':KNeighborsClassifier(n_neighbors = 17), 'feature_set':['liveness', 'tempo', 'acousticness', 'danceability']},\n",
    "#          {'title':\"Oversampling KNN\", 'model':make_pipeline_imb(SMOTE(random_state=4), KNeighborsClassifier(n_neighbors = 17)), 'feature_set':['energy', 'instrumentalness', 'duration', 'valence', 'mode']},\n",
    "#          {'title':\"SVM\", 'model':svm.SVC(probability=True, gamma='scale', random_state=3), 'feature_set':['liveness', 'tempo', 'acousticness', 'danceability', 'loudness', 'mode']},\n",
    "#           {'title':\"SVM balanced weights\", 'model':svm.SVC(probability=True, gamma='scale',class_weight='balanced', kernel='rbf'), 'feature_set':['speechiness', 'key']},\n",
    "#          {'title':\"Oversampling SVM\", 'model':make_pipeline_imb(SMOTE(random_state=4), svm.SVC(probability=True, gamma='scale', random_state=3, kernel='rbf')), 'feature_set':['tempo', 'time_signature']},\n",
    "#           {'title':\"Multilayer Perceptron\", 'model':MLPClassifier(solver='lbfgs', alpha=1e-2), 'feature_set':['energy', 'acousticness', 'danceability', 'duration', 'valence', 'mode']},\n",
    "#          {'title':\"Multilayer Perceptron\", 'model':MLPClassifier(), 'feature_set':['energy', 'acousticness', 'danceability', 'duration', 'valence', 'mode']},\n",
    "#          {'title':\"Oversampling Multilayer Perceptron\", 'model':make_pipeline_imb(SMOTE(random_state=4), MLPClassifier(solver=\"lbfgs\", activation=\"relu\", alpha=0.00001, learning_rate=\"adaptive\",random_state=3, hidden_layer_sizes=(50, 100, 50))), 'feature_set':['loudness', 'speechiness']},\n",
    "          {'title':\"SGD Multilayer Perceptron\", 'model':MLPClassifier(activation = 'relu', solver='sgd', alpha=0.0001, learning_rate=\"adaptive\"), 'feature_set':['loudness', 'speechiness']},\n",
    "#          {'title':\"Random Forest Classifier balanced weights\", 'model':RandomForestClassifier(n_estimators=100, max_depth=2, random_state=3, class_weight=\"balanced\", n_jobs=-1), 'feature_set':['loudness', 'speechiness']}\n",
    "         ]\n",
    "models_scores_list = []\n",
    "\n",
    "for item in models:\n",
    "    steps_taken = 0\n",
    "    scores_list = []\n",
    "    # Loop thorugh all the different subsets of 1,2,3, ..., (#features) elements\n",
    "    for n_elem_subsets in range(0, len(columns), 1):\n",
    "        len_elem_subs = len(allSubsets[n_elem_subsets])\n",
    "#         best_score = 0\n",
    "#         best_feature_set = []\n",
    "        \n",
    "        # Loop through all the subsets of n_elem_subsets elements\n",
    "        for cur_comb in range(0, len_elem_subs, 1):\n",
    "\n",
    "            # Current feature set\n",
    "            cur_feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "\n",
    "            # Get the data with the current subset of features\n",
    "            cur_data = X_fs[cur_feature_set]\n",
    "\n",
    "            # Transform to np array for faster computation\n",
    "            cur_data_np = np.array(cur_data)\n",
    "            cur_labels_np = np.array(y_fs)\n",
    "            \n",
    "            # Counter of number of iterations\n",
    "            steps_taken += 1\n",
    "            if steps_taken % 1000 == 0:\n",
    "                print(steps_taken)\n",
    "\n",
    "            # Instantiate model\n",
    "            model = item['model']\n",
    "            # model = svm.SVC(probability=True, gamma='scale', random_state=3, class_weight='balanced')\n",
    "\n",
    "            # Instantiate cross validation strategy\n",
    "            cv = StratifiedShuffleSplit(n_splits=10, random_state=5)\n",
    "\n",
    "            scores = np.array([])\n",
    "            for train, test in cv.split(cur_data_np, cur_labels_np):\n",
    "                probas_ = model.fit(cur_data_np[train], cur_labels_np[train]).predict_proba(cur_data_np[test])\n",
    "                predicts = model.predict(cur_data_np[test])\n",
    "                scores = np.append(scores, roc_auc_score(cur_labels_np[test], probas_[:, 1]))\n",
    "\n",
    "            mean_score = scores.mean()\n",
    "\n",
    "            # average_score = (float(mean_score) + test_after_auc)/2\n",
    "            # print(\"Curent score for {} features : {} | Test after score: {} | Average: {}\".format(len(cur_feature_set), mean_score, test_after_auc, average_score))\n",
    "\n",
    "            # For brevity, we only keep the best feature subset of one size\n",
    "            # Alternatively, we could keep the scores for all the different combinations\n",
    "#             if mean_score > best_score:\n",
    "#                 best_score = mean_score\n",
    "#                 best_feature_set = list(allSubsets[n_elem_subsets][cur_comb])\n",
    "\n",
    "            #predictions = model.predict(X_test[feature_set])\n",
    "            #model = item['model']\n",
    "            model.fit(cur_data_np, cur_labels_np)\n",
    "            y_pred_prob = model.predict_proba(X_test[cur_feature_set])[:,1]\n",
    "            test_after_auc = roc_auc_score(y_test, y_pred_prob)   \n",
    "            #Keep the best score in a list    \n",
    "            scores_list.append([cur_feature_set, test_after_auc, mean_score])\n",
    "\n",
    "    print(\"Number of iterations: \", steps_taken)\n",
    "    models_scores_list.append([item['title'], scores_list])\n",
    "    \n",
    "    max_score_gen = 0\n",
    "    max_score_cv = 0\n",
    "    score_cv = 0\n",
    "    score_gen = 0\n",
    "    sel_feature_set_gen = []\n",
    "    sel_feature_set_cv = []\n",
    "    for i in range(0, len(scores_list), 1):\n",
    "        cur_score_gen = scores_list[i][1]\n",
    "        cur_score_cv = scores_list[i][2]\n",
    "        #print(cur_score)\n",
    "        if cur_score_gen > max_score_gen:\n",
    "            max_score_gen = cur_score_gen\n",
    "            score_cv = cur_score_cv\n",
    "            sel_feature_set_gen = scores_list[i][0]\n",
    "            \n",
    "        if cur_score_cv > max_score_cv:\n",
    "            max_score_cv = cur_score_cv\n",
    "            score_gen = cur_score_gen\n",
    "            sel_feature_set_cv = scores_list[i][0]\n",
    "    print(item['title'])\n",
    "    print()\n",
    "    print(\"Max generalized score: \")\n",
    "    print(max_score_gen)\n",
    "    print(\"Average cv score for that feature subset: \")\n",
    "    print(score_cv)\n",
    "    print()\n",
    "    print(sel_feature_set_gen)\n",
    "    print(\"-------------------\")\n",
    "    print(\"Max average cv score: \")\n",
    "    print(max_score_cv)\n",
    "    print(\"Generalized score for that feature subset: \")\n",
    "    print(score_gen)\n",
    "    print()\n",
    "    print(sel_feature_set_cv)\n",
    "    print()\n",
    "    print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring looks like: \n",
    "[Model Name, [feature subset, generalize score, average cv score]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=5)\n",
    "\n",
    "sel = SelectKBest(chi2, k = 5)\n",
    "sel.fit(X_train, y_train)\n",
    "\n",
    "selected = sel.transform(X_train)\n",
    "#print(selected.shape)\n",
    "#print(X_train.shape)\n",
    "\n",
    "mask = sel.get_support() #list of booleans\n",
    "new_features = [] # The list of your K best features\n",
    "\n",
    "for bool, feature in zip(mask, columns):\n",
    "    if bool:\n",
    "        new_features.append(feature)\n",
    "print(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(pearsonr(X['valence'], y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danceability 0.0\n",
      "key 0.0\n",
      "loudness 0.0\n",
      "mode 0.0\n",
      "time_signature 0.0\n",
      "instrumentalness 0.000894091894609\n",
      "duration 0.00394051170442\n",
      "valence 0.0052091734451\n",
      "acousticness 0.0064337769563\n",
      "energy 0.00782331422319\n",
      "liveness 0.0090491953887\n",
      "speechiness 0.010764084423\n",
      "tempo 0.0248102732113\n",
      "youtube_view_count 0.0767909877769\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "feature_scores = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, columns)):\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JMI for energy is 0.153979386369\n",
      "JMI for liveness is 0.244123657293\n",
      "JMI for tempo is 0.562840650098\n",
      "JMI for speechiness is 0.757750987721\n",
      "JMI for acousticness is 0.848489219212\n",
      "JMI for instrumentalness is 0.932732553967\n",
      "JMI for time_signature is 1.01245219852\n",
      "JMI for danceability is 1.01245219852\n",
      "JMI for key is 1.02259786753\n",
      "JMI for duration is 1.07382451968\n",
      "JMI for loudness is 1.07382451968\n",
      "JMI for valence is 1.19773610499\n",
      "JMI for mode is 1.39765128205\n",
      "JMI for youtube_view_count is 2.39593412315\n"
     ]
    }
   ],
   "source": [
    "columns = [\"energy\", \"liveness\", \"tempo\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"time_signature\", \"danceability\",\n",
    "          \"key\", \"duration\", \"loudness\", \"valence\", \"mode\", 'youtube_view_count']\n",
    "jmi = 0\n",
    "for col in columns:\n",
    "    for next_col in columns:\n",
    "        if col != next_col:\n",
    "            jmi += mutual_info_classif(X_train[[col, next_col]], y_train)[0]\n",
    "            #print(col, next_col)\n",
    "    print(\"JMI for {} is {}\".format(col, jmi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loudness 0.00568406128276\n",
      "speechiness 0.0270260029669\n",
      "time_signature 0.0319876660937\n",
      "duration 0.185910425031\n",
      "liveness 0.18892589418\n",
      "mode 0.280688060472\n",
      "instrumentalness 0.499371675555\n",
      "key 0.824257236616\n",
      "danceability 1.7323999922\n",
      "acousticness 2.37542137751\n",
      "energy 2.55239718842\n",
      "tempo 2.90091388799\n",
      "valence 9.47236752793\n",
      "youtube_view_count 16.7542628848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "feature_scores = f_classif(X_train, y_train)[0]\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, columns)):\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.100676893575\n",
      "test score:  -0.0245044946864\n",
      "number of features used:  5\n",
      "Alpha(amount of penalization) chosen by CV:  0.00255186972012\n",
      "['tempo', 'acousticness', 'danceability', 'valence', 'youtube_view_count']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "lasso = LassoCV(cv=StratifiedKFold(n_splits=10, random_state=3), random_state=3)\n",
    "lasso.fit(X_train,y_train)\n",
    "train_score=lasso.score(X_train,y_train)\n",
    "test_score=lasso.score(X_test,y_test)\n",
    "coeff_used = np.sum(lasso.coef_!=0)\n",
    "\n",
    "print(\"training score:\", train_score)\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)\n",
    "\n",
    "#print(lasso.coef_)\n",
    "\n",
    "ind = 0\n",
    "sel_f = []\n",
    "for coef in lasso.coef_:\n",
    "    if coef != 0:\n",
    "        sel_f.append(columns[ind]) \n",
    "    ind += 1\n",
    "print(\"Alpha(amount of penalization) chosen by CV: \", lasso.alpha_)\n",
    "print(sel_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.733333333333\n",
      "test score:  0.754385964912\n",
      "number of features used:  8\n",
      "[[-0.94486389  0.         -0.7416253   0.         -0.74908941  0.          0.\n",
      "   1.26044335  0.          0.          1.61691455 -3.32279006  0.21806523\n",
      "   6.60718735]]\n",
      "['energy', 'tempo', 'acousticness', 'danceability', 'loudness', 'valence', 'mode', 'youtube_view_count']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "loglasso = LogisticRegression(penalty='l1', class_weight='balanced', random_state=3)\n",
    "loglasso.fit(X_train,y_train)\n",
    "train_score=loglasso.score(X_train,y_train)\n",
    "test_score=loglasso.score(X_test,y_test)\n",
    "coeff_used = np.sum(loglasso.coef_!=0)\n",
    "\n",
    "print(\"training score:\", train_score)\n",
    "print(\"test score: \", test_score)\n",
    "print(\"number of features used: \", coeff_used)\n",
    "\n",
    "print(loglasso.coef_)\n",
    "\n",
    "ind = 0\n",
    "sel_f = []\n",
    "for coef in loglasso.coef_[0]:\n",
    "    if coef != 0:\n",
    "        sel_f.append(columns[ind]) \n",
    "    ind += 1\n",
    "print(sel_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
