{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = \"https://kworb.net/spotify/country/global_weekly_totals.html\"\n",
    "response = requests.get(url)\n",
    "response.text[:100] # Access the HTML with the text property\n",
    "#print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code from here https://srome.github.io/Parsing-HTML-Tables-in-Python-with-BeautifulSoup-and-pandas/\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "class HTMLTableParser:\n",
    "\n",
    "    def parse_url(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        return [(table,self.parse_html_table(table))\\\n",
    "                for table in soup.find_all('table')]  \n",
    "\n",
    "    def parse_html_table(self, table):\n",
    "        n_columns = 0\n",
    "        n_rows=0\n",
    "        column_names = []\n",
    "\n",
    "        # Find number of rows and columns\n",
    "        # we also find the column titles if we can\n",
    "        for row in table.find_all('tr'):\n",
    "\n",
    "            # Determine the number of rows in the table\n",
    "            td_tags = row.find_all('td')\n",
    "            if len(td_tags) > 0:\n",
    "                n_rows+=1\n",
    "                if n_columns == 0:\n",
    "                    # Set the number of columns for our table\n",
    "                    n_columns = len(td_tags)\n",
    "\n",
    "            # Handle column names if we find them\n",
    "            th_tags = row.find_all('th') \n",
    "            if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                for th in th_tags:\n",
    "                    column_names.append(th.get_text())\n",
    "\n",
    "        # Safeguard on Column Titles\n",
    "        if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "            raise Exception(\"Column titles do not match the number of columns\")\n",
    "\n",
    "        columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "        df = pd.DataFrame(columns = columns,\n",
    "                          index= range(0,n_rows))\n",
    "        row_marker = 0\n",
    "        for row in table.find_all('tr'):\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                if column_marker == 1:\n",
    "                    df.iat[row_marker,column_marker] = column.get_text() + \"||\" + column.find_all('a')[1]['href']\n",
    "                else:\n",
    "                    df.iat[row_marker,column_marker] = column.get_text()\n",
    "                column_marker += 1\n",
    "            if len(columns) > 0:\n",
    "                row_marker += 1\n",
    "\n",
    "        # Convert to float if possible\n",
    "        for col in df:\n",
    "            try:\n",
    "                df[col] = df[col].astype(float)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HTMLTableParser()\n",
    "table = hp.parse_url(\"https://kworb.net/spotify/country/global_weekly_totals.html\")[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table['Artist and Title'][0].split(\"||\")[1].split('/')[2].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(\"new_data.csv\", encoding=\"utf-8\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate with Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function    # (at top of module)\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import json\n",
    "import spotipy\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import seaborn as sns\n",
    "import config\n",
    "\n",
    "\n",
    "# Spotify API Setup\n",
    "client_credentials_manager = SpotifyClientCredentials(config.client_id, config.client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "# Enables verbose JSON requests tracing\n",
    "sp.trace=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name to write to\n",
    "fileName = \"newdata_combined_2013_2019.csv\"\n",
    "\n",
    "# Columns for my pandas DataFrame in which we will keep the data\n",
    "columns = [\"song_id\",\"song_title\", \"artist\", \"popularity\", \"total_no_streams\", \"energy\", \"liveness\", \"tempo\"\n",
    "          , \"speechiness\", \"acousticness\", \"instrumentalness\", \"time_signature\", \"danceability\",\n",
    "          \"key\", \"duration\", \"loudness\", \"valence\", \"mode\"]\n",
    "\n",
    "# Actual data structure for the data\n",
    "myData = []\n",
    "\n",
    "count = 0\n",
    "for index, row in table.iterrows():\n",
    "    track = sp.track(\"spotify:track:\" + row['Artist and Title'].split(\"||\")[1].split('/')[2].split('.')[0])\n",
    "    #print(result['tracks']['items'][0]['name'])\n",
    "\n",
    "    trackId = track['uri']\n",
    "    songTitle = track['name']\n",
    "    popularity = int(track['popularity'])\n",
    "\n",
    "    # A song might have more than one artist so we make a list of all of them\n",
    "    artistName = []\n",
    "    for artist in track['artists']:\n",
    "        artistName.append(artist['name'])\n",
    "\n",
    "    # Get features for the track\n",
    "    features = sp.audio_features([trackId])\n",
    "\n",
    "    # If the feature array is empty this usually means something has gone wrong \n",
    "    # with the request so this stops the program from failing in that case\n",
    "    if features[0] != None :\n",
    "        energy = features[0]['energy']\n",
    "        liveness = features[0]['liveness'] \n",
    "        tempo = features[0]['tempo']\n",
    "        speechiness = features[0]['speechiness']\n",
    "        acousticness = features[0]['acousticness']\n",
    "        instrumentalness = features[0]['instrumentalness']\n",
    "        time_signature = features[0]['time_signature']\n",
    "        danceability = features[0]['danceability']\n",
    "        key = features[0]['key']\n",
    "        duration_ms = features[0]['duration_ms']\n",
    "        loudness = features[0]['loudness']\n",
    "        valence = features[0]['valence']\n",
    "        mode = features[0]['mode']\n",
    "        total_no_streams = int(row['Total'].replace(',', ''))\n",
    "    newRow = [trackId,songTitle, artistName, popularity, total_no_streams,energy, liveness, tempo, speechiness, acousticness, instrumentalness, time_signature,\n",
    "              danceability, key, duration_ms, loudness, valence, mode]\n",
    "    #print(newRow)\n",
    "    # Add the new row to our existing data\n",
    "    myData.append(newRow)\n",
    "    count += 1\n",
    "    if(count % 100 == 0):\n",
    "        print(\"Processed \" + str(count) + \" songs so far.\")\n",
    "    time.sleep(0.1)\n",
    "print(\"Finished processing.\")\n",
    "df = pd.DataFrame(myData, columns=columns)\n",
    "df.head()\n",
    "print(\"Writing file to CSV...\")\n",
    "df.to_csv(fileName, encoding=\"utf-8\", header=True, index=False)\n",
    "print(\"Done.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the CSV to make sure everything is fine\n",
    "data = pd.read_csv(\"google_cleaned_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of entries in original data: \" + str(len(data.index)))\n",
    "data['popularity'] = pd.to_numeric(data['popularity'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
