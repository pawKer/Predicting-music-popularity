{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function    # (at top of module)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import json\n",
    "import spotipy\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "from matplotlib.pyplot import figure\n",
    "import math\n",
    "import seaborn as sns\n",
    "import io, os, sys, types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used to save the models to a file as a pickle representation so they can be loaded later into the web app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the file\n",
    "data = pd.read_csv('Data/data_500_entries_youtube.csv')\n",
    "print(\"Number of entries in original data: \" + str(len(data.index)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project_modules import *\n",
    "\n",
    "#final_data = label_data_combined(data, 90, 1000000000)\n",
    "final_data = label_data_yt(data, 89, 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns from original data - also some legacy support for a different data format\n",
    "if 'song_id' in data.columns:\n",
    "    final_data.drop(['song_id', 'song_title', 'artist', 'popularity', 'youtube_view_count', 'youtube_video_title'], 1, inplace=True)\n",
    "else:\n",
    "    final_data.drop(['song_title', 'artist', 'popularity'], 1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X will be our examples and y will be our labels\n",
    "X = final_data.drop('is_popular', axis=1)\n",
    "y = final_data['is_popular']\n",
    "# Sanity checks\n",
    "print(\"Number of entries in actual data: \" + str(len(X.index)))\n",
    "print(\"Number of entries in label data: \" + str(len(y.index)))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "COLUMNS_TO_SCALE = [\"energy\", \"liveness\", \"tempo\", \n",
    "                    \"speechiness\", \"acousticness\", \"instrumentalness\", \n",
    "                    \"time_signature\", \"danceability\", \"key\", \n",
    "                    \"duration\", \"loudness\", \"valence\", \"mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(y))\n",
    "sm = SMOTE()\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "print(Counter(y_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pickle to write the models and a scaler to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also keep a scaler because if we just use certain features a scaler that was fitted on data with all the features won't work. Also we need the scaler to scale new examples the same way we scaled our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "# For each with less features we need own scaler which we need to export\n",
    "#['energy', 'tempo', 'instrumentalness', 'danceability', 'loudness', 'valence'\n",
    "scaler1 = preprocessing.StandardScaler()\n",
    "scaler1.fit(X[['energy', 'tempo', 'instrumentalness', 'danceability', 'loudness', 'valence']])\n",
    "pickle.dump(scaler1, open(\"3yp_scaler_log.pkl\",\"wb\"))\n",
    "# Copy data back\n",
    "X_log = scaler1.transform(X[['energy', 'tempo', 'instrumentalness', 'danceability', 'loudness', 'valence']])\n",
    "\n",
    "model1 = LogisticRegression(solver='lbfgs',class_weight='balanced', random_state=3)\n",
    "model1.fit(X_log, y)\n",
    "\n",
    "pickle.dump(model1, open(\"3yp_log.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "#['energy', 'tempo', 'speechiness', 'instrumentalness', 'time_signature', 'duration', 'loudness']\n",
    "scaler2 = preprocessing.StandardScaler()\n",
    "scaler2.fit(X[['energy', 'tempo', 'speechiness', 'instrumentalness', 'time_signature', 'duration', 'loudness']])\n",
    "pickle.dump(scaler2, open(\"3yp_scaler_svm.pkl\",\"wb\"))\n",
    "# Copy data back\n",
    "X_svm = scaler2.transform(X[['energy', 'tempo', 'speechiness', 'instrumentalness', 'time_signature', 'duration', 'loudness']])\n",
    "\n",
    "model2 = svm.SVC(probability=True, gamma='scale', class_weight='balanced')\n",
    "model2.fit(X_svm, y)\n",
    "\n",
    "pickle.dump(model2, open(\"3yp_svm.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "# all\n",
    "\n",
    "scaler3 = preprocessing.StandardScaler()\n",
    "scaler3.fit(X)\n",
    "pickle.dump(scaler3, open(\"3yp_scaler_mlp_smote.pkl\",\"wb\"))\n",
    "# Copy data back\n",
    "X_mlp_smote = scaler3.transform(X)\n",
    "model3 = make_pipeline_imb(SMOTE(), MLPClassifier(solver=\"lbfgs\", activation=\"relu\", alpha=1, learning_rate=\"constant\")\n",
    "model3.fit(X_mlp_smote,y)\n",
    "\n",
    "pickle.dump(model3, open(\"3yp_mlp_smote.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4\n",
    "# all\n",
    "# Try to also fit with oversampled data\n",
    "\n",
    "scaler4 = preprocessing.StandardScaler()\n",
    "scaler4.fit(X)\n",
    "pickle.dump(scaler4, open(\"3yp_scaler_mlp_online.pkl\",\"wb\"))\n",
    "X_mlp_online = scaler4.transform(X)\n",
    "\n",
    "print(Counter(y))\n",
    "sm2 = SMOTE()\n",
    "X_res_mlp, y_res_mlp = sm2.fit_resample(X_mlp_online, y)\n",
    "print(Counter(y_res))\n",
    "\n",
    "model4 = MLPClassifier(activation = 'relu', solver='sgd', alpha=0.0001, learning_rate=\"constant\")\n",
    "model4.fit(X_res_mlp, y_res_mlp)\n",
    "\n",
    "pickle.dump(model4, open(\"3yp_mlp_online.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5\n",
    "# ['energy', 'liveness', 'tempo', 'acousticness', 'instrumentalness', 'time_signature', 'duration', 'loudness', 'valence']\n",
    "scaler5 = preprocessing.StandardScaler()\n",
    "scaler5.fit(X)\n",
    "pickle.dump(scaler5, open(\"3yp_scaler_mlp_simple.pkl\",\"wb\"))\n",
    "# Copy data back\n",
    "X_mlp_simple = scaler5.transform(X)\n",
    "model5 = MLPClassifier(learning_rate=\"constant\", solver=\"adam\", alpha=0.001)\n",
    "model5.fit(X_mlp_simple,y)\n",
    "\n",
    "pickle.dump(model5, open(\"3yp_mlp_simple.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6\n",
    "# make_pipeline_imb(SMOTE(random_state=4), svm.SVC(probability=True, gamma='scale', random_state=3))\n",
    "# feature_set :['energy', 'tempo', 'speechiness', 'loudness', 'valence']\n",
    "scaler6 = preprocessing.StandardScaler()\n",
    "scaler6.fit(X[['energy', 'tempo', 'speechiness', 'loudness', 'valence']])\n",
    "pickle.dump(scaler6, open(\"3yp_scaler_svm_smote.pkl\",\"wb\"))\n",
    "# Copy data back\n",
    "X_svm_smote = scaler6.transform(X[['energy', 'tempo', 'speechiness', 'loudness', 'valence']])\n",
    "model6 = make_pipeline_imb(SMOTE(random_state=4), svm.SVC(probability=True, gamma='scale'))\n",
    "model6.fit(X_svm_smote,y)\n",
    "\n",
    "pickle.dump(model6, open(\"3yp_svm_smote.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with a set of new examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(config.client_id, config.client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_song = sp.audio_features([\"spotify:track:4kV4N9D1iKVxx1KLvtTpjS\" \n",
    "                               \"spotify:track:6ocbgoVGwYJhOv1GgI9NsF\",\n",
    "                               \"spotify:track:5WHTFyqSii0lmT9R21abT8\",\n",
    "                               \"spotify:track:2TIlqbIneP0ZY1O0EzYLlc\",\n",
    "                               \"spotify:track:5itOtNx0WxtJmi1TQ3RuRd\",\n",
    "                               \"spotify:track:1dAw715CaUd1HKGKXCzimK\",\n",
    "                               \"spotify:track:5n2KsLTepK1vPeIkMw7UpV\",\n",
    "                               \"spotify:track:6scFQGR5c6XYV33pcLbBIt\",\n",
    "                               \"spotify:track:38df12R7YuZj8fIkhS3nRp\",\n",
    "                                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_song1 = []\n",
    "for i in range(0, 8, 1):\n",
    "    test_song1.append([test_song[i]['energy'], test_song[i][\"liveness\"], test_song[i][\"tempo\"], \n",
    "                    test_song[i][\"speechiness\"], test_song[i][\"acousticness\"], test_song[i][\"instrumentalness\"], \n",
    "                    test_song[i][\"time_signature\"], test_song[i][\"danceability\"], test_song[i][\"key\"], \n",
    "                    test_song[i][\"duration_ms\"], test_song[i][\"loudness\"], test_song[i][\"valence\"], test_song[i][\"mode\"]])\n",
    "test_df = pd.DataFrame(test_song1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_song1)\n",
    "data_np = scaler3.transform(test_df)\n",
    "print(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = pickle.load(open(\"Webserver/models/3yp_mlp_smote.pkl\",\"rb\"))\n",
    "predicted_labels = model7.predict(data_np)\n",
    "print(predicted_labels)\n",
    "print()\n",
    "print()\n",
    "predicted_probabilities = model7.predict_proba(data_np)\n",
    "print(predicted_probabilities)\n",
    "print()\n",
    "print()\n",
    "for i in range(0, 8, 1):\n",
    "    #print(\"Predicted label: \", model.predict(data_np))\n",
    "    print(predicted_labels[i])\n",
    "    print(predicted_probabilities[i])\n",
    "    #print(\"Class 0 probability: \",model.predict_proba(data_np[i])[0][0],\" Class 1 probability: \",model.predict_proba(data_np[i])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
